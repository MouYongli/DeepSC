{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29718577",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from collections import defaultdict\n",
    "from deepsc.scgpt_utils.grn import GeneEmbedding\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "class GRNInference:\n",
    "    def __init__(self, args, fabric, model):\n",
    "        self.args = args\n",
    "        self.fabric = fabric\n",
    "        self.model = model\n",
    "\n",
    "        # 设备\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "        self.load_pretrained_model()\n",
    "\n",
    "        # 1) 读 CSV，构建映射\n",
    "        df = pd.read_csv(\"/home/angli/baseline/DeepSC/scripts/data/preprocessing/gene_map.csv\")\n",
    "        # feature_name -> id（允许重复 id）\n",
    "        self.gene2idx = dict(zip(df[\"feature_name\"], df[\"id\"]))\n",
    "        # id -> [feature_name, ...]（可选：用于反查）\n",
    "        self.idx2genes = defaultdict(list)\n",
    "        for name, i in zip(df[\"feature_name\"], df[\"id\"]):\n",
    "            self.idx2genes[int(i)].append(name)\n",
    "\n",
    "        # 2) 载入 AnnData\n",
    "        self.load_data()\n",
    "\n",
    "        # 3) 取嵌入\n",
    "        self.get_gene_embeddings()\n",
    "        embed=GeneEmbedding(self.gene2emb)\n",
    "\n",
    "        # Perform Louvain clustering with desired resolution; here we specify resolution=40\n",
    "        gdata = embed.get_adata(resolution=40)\n",
    "        # Retrieve the gene clusters\n",
    "        metagenes = embed.get_metagenes(gdata)\n",
    "\n",
    "        # Obtain the set of gene programs from clusters with #genes >= 5\n",
    "        mgs = dict()\n",
    "        for mg, genes in metagenes.items():\n",
    "            if len(genes) > 4:\n",
    "                mgs[mg] = genes\n",
    "        print(mgs)\n",
    "        # sns.set(font_scale=0.35)\n",
    "        # print(\"Scoring metagenes\")\n",
    "        # embed.score_metagenes(self.adata, metagenes)\n",
    "        # print(\"Plotting metagenes scores\")\n",
    "        # embed.plot_metagenes_scores(self.adata, mgs, \"celltype\")\n",
    "        # print(\"Saving metagenes scores\")\n",
    "        # plt.savefig(\"metagenes_scores.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        # plt.close()\n",
    "        # print(\"Metagenes scores saved\")\n",
    "\n",
    "    def load_data(self):\n",
    "        self.adata = ad.read_h5ad(self.args.data_path)\n",
    "        self.adata.obs[\"celltype\"] = self.adata.obs[\"final_annotation\"].astype(str)\n",
    "        sc.pp.highly_variable_genes(\n",
    "            self.adata,\n",
    "            layer=None,\n",
    "            n_top_genes=1200\n",
    "            if isinstance(1200, int)\n",
    "            else None,\n",
    "            batch_key=\"batch\",\n",
    "            flavor=\"seurat_v3\",\n",
    "            subset=True,\n",
    "        )\n",
    "        print(self.adata.shape)\n",
    "    def get_gene_embeddings(self):\n",
    "        \"\"\"\n",
    "        目标：\n",
    "        - 生成 2 个结构：\n",
    "          a) self.gene_embeddings_mat: (N, D) 矩阵，顺序与 features_aligned 一致\n",
    "          b) self.gene2emb: {gene_name -> embedding(np.ndarray)}\n",
    "        其中 N 是 adata.var.index 中出现、且在 gene_map.csv 中有 id 的基因数。\n",
    "        \"\"\"\n",
    "        # 仅保留在 adata 中出现的基因，并按照这些 gene 的顺序取 id\n",
    "        adata_genes = set(map(str, self.adata.var.index))\n",
    "        features_aligned = [g for g in self.gene2idx.keys() if g in adata_genes]\n",
    "\n",
    "        # 用真正的 id 列表（而不是 enumerate 的序号）\n",
    "        id_list = [int(self.gene2idx[g]) for g in features_aligned]\n",
    "\n",
    "        # as_tensor + 直接放到 device；避免对 tensor 再次 torch.tensor(...) 的告警\n",
    "        ids = torch.as_tensor(id_list, dtype=torch.long, device=self.device)\n",
    "\n",
    "        # 取 embedding（(N, D)）\n",
    "        with torch.no_grad():\n",
    "            emb_mat = self.model.gene_embedding(ids)\n",
    "\n",
    "        # 保存矩阵与字典（注意：名字不要再叫 gene_embeddings，避免冲突）\n",
    "        self.gene_embeddings_mat = emb_mat.cpu().numpy()              # shape: (N, D)\n",
    "        self.gene2emb = {g: self.gene_embeddings_mat[i]               # dict: gene -> np.ndarray(D,)\n",
    "                          for i, g in enumerate(features_aligned)}\n",
    "\n",
    "        print(f\"Retrieved gene embeddings for {len(self.gene2emb)} genes. \"\n",
    "              f\"Matrix shape: {self.gene_embeddings_mat.shape}\")\n",
    "\n",
    "        # （可选）如果还想拿“唯一 id 的嵌入”，再来一份去重版：\n",
    "        unique_ids = sorted(set(id_list))\n",
    "        unique_ids_t = torch.as_tensor(unique_ids, dtype=torch.long, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            emb_unique = self.model.gene_embedding(unique_ids_t).cpu().numpy()\n",
    "        # id -> emb\n",
    "        self.id2emb = {uid: emb_unique[j] for j, uid in enumerate(unique_ids)}\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "        ckpt_path = self.args.pretrained_model_path\n",
    "        assert os.path.exists(ckpt_path), f\"找不到 ckpt: {ckpt_path}\"\n",
    "        if self.fabric.global_rank == 0:\n",
    "            print(f\"[LOAD] 读取 checkpoint: {ckpt_path}\")\n",
    "            raw = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "            from deepsc.utils.utils import extract_state_dict_with_encoder_prefix, sample_weight_norms, report_loading_result\n",
    "            state_dict = extract_state_dict_with_encoder_prefix(raw)\n",
    "        else:\n",
    "            state_dict = None\n",
    "        state_dict = self.fabric.broadcast(state_dict, src=0)\n",
    "        sample_weight_norms(self.model, state_dict, k=5)\n",
    "        load_info = self.model.load_state_dict(state_dict, strict=False)\n",
    "        from deepsc.utils.utils import report_loading_result\n",
    "        report_loading_result(load_info)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
