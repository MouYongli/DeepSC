{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d838de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from collections import defaultdict\n",
    "from deepsc.scgpt_utils.grn import GeneEmbedding\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "from deepsc.utils.utils import extract_state_dict, sample_weight_norms, report_loading_result\n",
    "from deepsc.utils.utils import report_loading_result\n",
    "from deepsc.models.deepsc_new.model import DeepSC\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "import gseapy as gp\n",
    "from gears import PertData\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b358af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path=\"/home/angli/baseline/DeepSC/results/latest_checkpoint_epoch3.ckpt\"\n",
    "data_path_dir=\"/home/angli/baseline/DeepSC/data/\"\n",
    "gene_map_path=\"/home/angli/baseline/DeepSC/data/gene_map.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f208a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model( model, pretrained_model_path):\n",
    "    ckpt_path = pretrained_model_path\n",
    "    assert os.path.exists(ckpt_path), f\"找不到 ckpt: {ckpt_path}\"\n",
    "    print(f\"[LOAD] 读取 checkpoint: {ckpt_path}\")\n",
    "    raw = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    state_dict = extract_state_dict(raw)\n",
    "    sample_weight_norms(model, state_dict, k=5)\n",
    "    load_info = model.load_state_dict(state_dict, strict=False)\n",
    "    report_loading_result(load_info)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce176ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types # 导入 types 模块\n",
    "model_config = {\n",
    "    \"embedding_dim\": 256,\n",
    "    \"num_genes\": 34683,\n",
    "    \"num_layers\": 10,\n",
    "    \"num_heads\": 8,\n",
    "    \"attn_dropout\": 0.1,\n",
    "    \"ffn_dropout\": 0.1,\n",
    "    \"fused\": False,\n",
    "    \"num_bins\": 5,  # 从 Hydra 变量 ${num_bin} 转换\n",
    "    \"mask_layer_start\": 100,\n",
    "    \"enable_l0\": False,       # 从 Hydra 变量 ${enable_l0} 转换\n",
    "    \"enable_mse\": True,     # 从 Hydra 变量 ${enable_mse} 转换\n",
    "    \"enable_ce\": True,       # 从 Hydra 变量 ${enable_ce} 转换\n",
    "    \"num_layers_ffn\": 2,\n",
    "    \"use_moe_regressor\": True,\n",
    "    \"number_of_experts\": 3,\n",
    "    \"use_M_matrix\": False,\n",
    "    \"gene_embedding_participate_til_layer\": 3,\n",
    "    \"moe\": types.SimpleNamespace(**{\n",
    "        \"n_moe_layers\": 4,\n",
    "        \"use_moe_ffn\": True,\n",
    "        \"dim\": 256,\n",
    "        \"moe_inter_dim\": 512,\n",
    "        \"n_routed_experts\": 2,\n",
    "        \"n_activated_experts\": 2,\n",
    "        \"n_shared_experts\": 1,\n",
    "        \"score_func\": \"softmax\",\n",
    "        \"route_scale\": 1.0,\n",
    "        \"world_size\": 1,\n",
    "        \"rank\": 0,\n",
    "    })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a85ed53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSC(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c240c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7849862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] 读取 checkpoint: /home/angli/baseline/DeepSC/results/latest_checkpoint_epoch3.ckpt\n",
      "[LOAD] 抽样参数范数对比（加载前 -> 加载后）：\n",
      "  - expression_layers.2.expr_attn.W_V.bias: 0.558314 -> 0.608517\n",
      "  - expression_layers.4.norm_expr2.weight: 16.000000 -> 16.453827\n",
      "  - expression_layers.4.ffn_expr.shared_experts.w3.bias: 0.817375 -> 0.816993\n",
      "  - layers.9.ffn_gene.layers.0.0.bias: 1.171525 -> 1.164386\n",
      "  - layers.5.norm_gene2.bias: 0.000000 -> 0.180650\n",
      "[LOAD] missing_keys: 0 | unexpected_keys: 0\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_model(model, pretrained_model_path)\n",
    "device = next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90f82530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 读 CSV，构建映射\n",
    "df = pd.read_csv(gene_map_path)\n",
    "# feature_name -> id（允许重复 id）\n",
    "gene2idx = dict(zip(df[\"feature_name\"], df[\"id\"]))\n",
    "# id -> [feature_name, ...]（可选：用于反查）\n",
    "idx2genes = defaultdict(list)\n",
    "for name, i in zip(df[\"feature_name\"], df[\"id\"]):\n",
    "    idx2genes[int(i)].append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "154bc2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Found local copy...\n",
      "Found local copy...\n",
      "These perturbations are not in the GO graph and their perturbation can thus not be predicted\n",
      "['SRPR+ctrl' 'SLMO2+ctrl' 'TIMM23+ctrl' 'AMIGO3+ctrl' 'KCTD16+ctrl']\n",
      "Local copy of pyg dataset is detected. Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data_path_dir\")\n",
    "pert_data = PertData(data_dir)\n",
    "pert_data.load(data_name=\"adamson\")\n",
    "adata = sc.read(data_dir / \"adamson/perturb_processed.h5ad\")\n",
    "ori_batch_col = \"control\"\n",
    "adata.obs[\"celltype\"] = adata.obs[\"condition\"].astype(\"category\")\n",
    "adata.obs[\"str_batch\"] = adata.obs[\"control\"].astype(str)\n",
    "data_is_raw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef916efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 AnnData.var 里新建一列，把 gene_name 映射到 ID\n",
    "adata.var[\"id_in_vocab\"] = [1 if g in gene2idx else -1 for g in adata.var[\"gene_name\"]]\n",
    "\n",
    "# 取出所有基因的 id 数组\n",
    "gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "\n",
    "# 过滤掉映射不到 id 的基因\n",
    "adata = adata[:, adata.var[\"id_in_vocab\"] >= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54d541a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 24767 × 4079\n",
      "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name', 'celltype', 'str_batch'\n",
      "    var: 'gene_name', 'gene_id', 'id_in_vocab'\n",
      "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n"
     ]
    }
   ],
   "source": [
    "TF_name = 'BHLHE40'\n",
    "adata = adata[adata.obs.condition.isin(['{}+ctrl'.format(TF_name), 'ctrl'])].copy()\n",
    "np.unique(adata.obs.condition)\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4202ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_expression(input_values, num_bins=5):\n",
    "    \"\"\"对表达值进行离散化分箱\"\"\"\n",
    "    batch_size = input_values.shape[0]\n",
    "    discrete_input_bins = torch.zeros_like(input_values, dtype=torch.long)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        row_vals = input_values[i]\n",
    "        valid_mask = row_vals != -1.0\n",
    "        if valid_mask.any():\n",
    "            valid_vals = row_vals[valid_mask]\n",
    "            min_val = valid_vals.min()\n",
    "            max_val = valid_vals.max()\n",
    "            norm = (valid_vals - min_val) / (max_val - min_val + 1e-8)\n",
    "            bins = torch.floor(norm * (num_bins - 1)).long()\n",
    "            bins = torch.clamp(bins, 0, num_bins - 1) + 1\n",
    "            discrete_input_bins[i][valid_mask] = bins\n",
    "\n",
    "    return discrete_input_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75e677d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 24767 × 1200\n",
      "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name', 'celltype', 'str_batch'\n",
      "    var: 'gene_name', 'gene_id', 'id_in_vocab', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n",
      "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20', 'hvg'\n"
     ]
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    layer=None,\n",
    "    n_top_genes=1200,\n",
    "    batch_key=\"str_batch\",\n",
    "    flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    subset=False,\n",
    ")\n",
    "adata.var.loc[adata.var[adata.var.gene_name==TF_name].index, 'highly_variable'] = True\n",
    "adata = adata[:, adata.var[\"highly_variable\"]].copy()\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae066c9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse array length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m all_values  \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mA \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(adata\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m adata\u001b[38;5;241m.\u001b[39mX \n\u001b[0;32m----> 2\u001b[0m all_values \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m all_discrete_bins \u001b[38;5;241m=\u001b[39m discretize_expression(all_values, \u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsc/lib/python3.11/site-packages/scipy/sparse/_base.py:378\u001b[0m, in \u001b[0;36m_spbase.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse array length is ambiguous; use getnnz()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or shape[0]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse array length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "all_values  = adata.X.A if hasattr(adata.X, \"A\") else adata.X \n",
    "all_values = torch.tensor(all_values, dtype=torch.float)\n",
    "all_discrete_bins = discretize_expression(all_values, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c1ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
