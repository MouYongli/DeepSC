defaults:
  - _self_
  - model: deepsc
  - tasks: cell_type_annotation

# WandB settings
wandb_project: "DeepSC"

# Task type selection
# Options:
#   - "cell_type_annotation": Cell type annotation task
#   - "perturbation_prediction": Perturbation prediction task
#   - "grn_inference": Gene regulatory network inference task
task_type: "cell_type_annotation"

# File loading settings
chunksize: 4
shuffel_files_each_epoch: False

# Pretrained model settings
pretrained_model_path: "/home/angli/baseline/DeepSC/results/latest_checkpoint.ckpt"
load_pretrained_model: True

# Fine-tuning mode selection
# Options:
#   - "full": Full parameter fine-tuning (all model parameters)
#   - "head_only": Only fine-tune the classification head
finetune_mode: "full"

# Output and path settings
output_dir: "/home/angli/baseline/DeepSC/outputs/deepsc"
csv_path: "/home/angli/baseline/DeepSC/data/gene_map.csv"
ckpt_dir: "/home/angli/baseline/DeepSC/ckpts"

# Model architecture settings
use_moe_ffn: True
sequence_length: 1024
num_bin: 5

# Training hyperparameters
seed: 42
learning_rate: 3e-4
epoch: 10
batch_size: 32
grad_acc: 20

# Distributed training settings
num_device: 3
num_nodes: 1  # 节点数，与SLURM --nodes配置匹配

# Checkpoint and logging settings
valid_every: 200
save_ckpt_every: 200
log_on_wandb_every: 20
resume_last_training: True

# Learning rate scheduler settings
use_warmup: False
warmup_ratio: 0.03
use_warmup_with_decay: False
use_scbert_scheduler: True
use_mogaide_scheduler: False

# Debug settings
check_grad_flow: False  # 是否启用梯度检查 多卡的时候不需要启用

# Hydra configuration
hydra:
  # Logging configuration: https://hydra.cc/docs/tutorials/basic/running_your_app/logging/
  verbose: False
  # Logs to stdout and to a file.
  job_logging:
    handlers:
      console:
        class: logging.StreamHandler
        stream: ext://sys.stdout
      file:
        filename:
          ${hydra.runtime.output_dir}/${hydra.job.name}_${oc.select:hydra.job.num, 0}.log
